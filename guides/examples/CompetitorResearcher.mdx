---
title: "Competitor Researcher"
sidebarTitle: "Competitor Researcher"
icon: "pen"
description: "This guide will walk you through setting up a system that scrapes competitor websites
and automatically adds detailed research notes to your Notion workspace. Let's get started!"
---
<Steps>
    <Step title="Install packages and Connect tools">
    First, install the necessary packages and connect your Notion account using composio cli so agents can use it. Run the following commands on your terminal:
    <CodeGroup>
        ```bash Run Command
        # Install dependencies
        pip install crewai==0.28.8

        # Composio SDK
        composio-cli update
        composio-cli login
        composio-cli add notion
        ```
    </CodeGroup>
    </Step>
    <Step title="Import base packages">
    In your Python script, import the required libraries:
    <CodeGroup>
        ```python Import statements
        import os, re, time, requests, base64, dotenv
        from bs4 import BeautifulSoup
        from datetime import datetime
        from flask import Flask, jsonify
        from openai import OpenAI, OpenAIError
        from composio_crewai import ComposioToolSet, App, ComposioSDK
        from crewai import Agent, Task
        from langchain_openai import ChatOpenAI
        ```
    </CodeGroup>
    </Step>
    <Step title="Initialise Agents using CrewAI">
    Initialize your agents and tools. Ensure you have your environment variables set up, especially your OpenAI API key.
    <CodeGroup>
        ```python CrewAI Agents
        dotenv.load_dotenv()
        llm = ChatOpenAI(openai_api_key=os.environ["OPENAI_API_KEY"], model_name="gpt-4-turbo-preview")

        composio_crewai = ComposioToolSet([App.NOTION])

        date = datetime.today().strftime('%Y-%m-%d')

        timezone = datetime.now().astimezone().tzinfo
        ```
    </CodeGroup>
    </Step>
    <Step title="Scrape Webpage">
    Define a function to scrape the competitor's website and extract the information you need.
    <CodeGroup>
        ```python Web Server in flask
        def remove_tags(html):
            soup = BeautifulSoup(html, "html.parser")
            return soup.get_text()

        def get_info(content):
            # Implement your logic to extract and format information from the content
            info = {
                "Summary": "Detailed competitor analysis goes here",
                "Key Points": "Key points extracted from the website content"
            }
            return info

        def scrape_website(url):
            content = []
            reqs = requests.get(url)
            content.append(remove_tags(reqs.content))
            cleaned_content = "\n".join(content)
            competitor_info = get_info(cleaned_content)
            return jsonify(competitor_info)        
    ```

    </CodeGroup>
    </Step>

    <Step title="Execute Agent">
    Set up the agent that will interact with Notion and create the required pages with the scraped data.
    <CodeGroup>
        ```python Run agent
        def step_callback(step):
    print(f"Step: {step}")

    agent = Agent(
        role="Notion Agent",
        goal="Take action on Notion.",
        backstory="You are an AI Agent with access to Notion",
        verbose=True,
        tools=composio_crewai,
        llm=llm,
        step_callback=step_callback,
    )

    url = "http://competitor-website.com"  # Replace with the actual URL
    parent_page = "Competitors"  # Replace with the actual parent page in Notion
    competitor_data = scrape_website(url).get_json()

    task = Task(
        description=f"Create a page for the competitor with the specified name. If a page with the same name already exists, append a unique identifier as a prefix or suffix. Create the page under '{parent_page}', if the parent page '{parent_page}' doesn't exist, find the most suitable parent page among existing pages. Place the pointers given to you in the created page without altering them. \nPointers to be included in the page: {competitor_data}. \nYour task ends only after successfully putting in the pointers in the page that you created.",
        expected_output="List down the contents of the page and title of the page created.",
        agent=agent,
        async_execution=True,
    )

    task.execute()        
    ```

    </CodeGroup>
    </Step>

</Steps>

## Putting it All Together
<CodeGroup>
    ```python Final Code
    import os, re, time, requests, base64, dotenv
    from bs4 import BeautifulSoup
    from datetime import datetime
    from flask import Flask, jsonify
    from openai import OpenAI, OpenAIError
    from composio_crewai import ComposioToolSet, App, ComposioSDK
    from crewai import Agent, Task
    from langchain_openai import ChatOpenAI

    dotenv.load_dotenv()
    llm = ChatOpenAI(openai_api_key=os.environ["OPENAI_API_KEY"], model_name="gpt-4-turbo-preview")
    composio_crewai = ComposioToolSet([App.NOTION])

    date = datetime.today().strftime('%Y-%m-%d')
    timezone = datetime.now().astimezone().tzinfo

    def remove_tags(html):
        soup = BeautifulSoup(html, "html.parser")
        return soup.get_text()

    def get_info(content):
        info = {
            "Summary": "Detailed competitor analysis goes here",
            "Key Points": "Key points extracted from the website content"
        }
        return info

    def scrape_website(url):
        content = []
        reqs = requests.get(url)
        content.append(remove_tags(reqs.content))
        cleaned_content = "\n".join(content)
        competitor_info = get_info(cleaned_content)
        return jsonify(competitor_info)

    def step_callback(step):
        print(f"Step: {step}")

    agent = Agent(
        role="Notion Agent",
        goal="Take action on Notion.",
        backstory="You are an AI Agent with access to Notion",
        verbose=True,
        tools=composio_crewai,
        llm=llm,
        step_callback=step_callback,
    )

    url = "http://competitor-website.com"  # Replace with the actual URL
    parent_page = "Competitors"  # Replace with the actual parent page in Notion
    competitor_data = scrape_website(url).get_json()

    task = Task(
        description=f"Create a page for the competitor with the specified name. If a page with the same name already exists, append a unique identifier as a prefix or suffix. Create the page under '{parent_page}', if the parent page '{parent_page}' doesn't exist, find the most suitable parent page among existing pages. Place the pointers given to you in the created page without altering them. \nPointers to be included in the page: {competitor_data}. \nYour task ends only after successfully putting in the pointers in the page that you created.",
        expected_output="List down the contents of the page and title of the page created.",
        agent=agent,
        async_execution=True,
    )

    task.execute()

    ```
</CodeGroup>
## Information
- [Github](https://github.com/anonthedev/competitor-researcher)
